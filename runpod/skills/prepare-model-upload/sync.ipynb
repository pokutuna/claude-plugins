{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# HuggingFace Model â†’ RunPod Network Volume\n\nColab ã§ HuggingFace ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€RunPod ã® Network Volume ã« S3 äº’æ› API ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚\n\n## Colab Secrets ã«ä»¥ä¸‹ã‚’è¨­å®š\n\n1. å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã® ğŸ”‘ ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯\n2. ä»¥ä¸‹ã® Secrets ã‚’è¿½åŠ :\n   - `HF_TOKEN`: HuggingFace ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³\n   - `RUNPOD_STORAGE_ACCESS_KEY_ID`: RunPod Storage ã® Access Key ID\n   - `RUNPOD_STORAGE_SECRET_ACCESS_KEY`: RunPod Storage ã® Secret Access Key\n3. å„ Secret ã®ã€ŒNotebook accessã€ã‚’ã‚ªãƒ³ã«ã™ã‚‹\n\n## RunPod Storage è¨­å®šã®å–å¾—\n\n1. https://console.runpod.io/user/storage ã‚’é–‹ã\n2. å¯¾è±¡ Volume ã®ã€ŒS3 Compatible API Commandsã€ã® Example ã‚’ã‚³ãƒ”ãƒ¼\n   ```\n   aws s3 ls --region xxx --endpoint-url https://s3api-xxx.runpod.io s3://your-volume-id/\n   ```\n3. ä¸‹ã®ã‚»ãƒ«ã« REGION, ENDPOINT_URL, BUCKET ã‚’è¨­å®š"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==================================================\n# è¨­å®š\n# ==================================================\nfrom google.colab import userdata\n\n# èªè¨¼æƒ…å ±\n%env HF_TOKEN={userdata.get('HF_TOKEN')}\n%env AWS_ACCESS_KEY_ID={userdata.get('RUNPOD_STORAGE_ACCESS_KEY_ID')}\n%env AWS_SECRET_ACCESS_KEY={userdata.get('RUNPOD_STORAGE_SECRET_ACCESS_KEY')}\n\n# HuggingFace ãƒ¢ãƒ‡ãƒ« (è¤‡æ•°æŒ‡å®šå¯)\n# https://huggingface.co/USER/REPOSITORY ã® USER/REPOSITORY ã‚’æŒ‡å®š\nHF_MODELS = [\n    \"Qwen/Qwen3-8B\",\n]\n\n# RunPod Storage è¨­å®š\n# https://console.runpod.io/user/storage ã® Example ã‹ã‚‰ã‚³ãƒ”ãƒ¼\n# ä¾‹: aws s3 ls --region xxx --endpoint-url https://s3api-xxx.runpod.io s3://your-volume-id/\nREGION = \"\"  # @param {type:\"string\"}\nENDPOINT_URL = \"\"  # @param {type:\"string\"}\nBUCKET = \"\"  # @param {type:\"string\"}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install -q huggingface_hub[hf_transfer]\n",
    "!pip install -q awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ & ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "for model in HF_MODELS:\n",
    "    local_dir = f\"/content/models/{model}\"\n",
    "    dest_path = f\"models/{model.split('/')[-1]}\"\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"=== {model} ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "    print(f\"\\n[1/3] Downloading {model}...\")\n",
    "    !HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download {model} --local-dir={local_dir}\n",
    "\n",
    "    # ç¢ºèª\n",
    "    print(f\"\\n[2/3] Downloaded files:\")\n",
    "    !du -sh {local_dir}\n",
    "\n",
    "    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    print(f\"\\n[3/3] Uploading to s3://{BUCKET}/{dest_path}...\")\n",
    "    !aws s3 sync {local_dir} s3://{BUCKET}/{dest_path} \\\n",
    "        --region={REGION} \\\n",
    "        --endpoint-url={ENDPOINT_URL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\n",
    "\n",
    "### ä¸€éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆ\n",
    "\n",
    "`upload failed` ãŒå‡ºãŸå ´åˆã¯ checksum ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã§å†å®Ÿè¡Œ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä»˜ãã§å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (å¤±æ•—æ™‚ç”¨)\n",
    "# for model in HF_MODELS:\n",
    "#     local_dir = f\"/content/models/{model}\"\n",
    "#     dest_path = f\"models/{model.split('/')[-1]}\"\n",
    "#     !aws s3 sync {local_dir} s3://{BUCKET}/{dest_path} \\\n",
    "#         --region={REGION} \\\n",
    "#         --endpoint-url={ENDPOINT_URL} \\\n",
    "#         --checksum-algorithm=CRC32C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume ãŒå¤§ãã sync ãŒå¤±æ•—ã™ã‚‹å ´åˆ\n",
    "\n",
    "> fatal error: Error during pagination: The same next token was received twice: ...\n",
    "\n",
    "`cp --recursive` ã‚’ä½¿ç”¨ (å·®åˆ†è»¢é€ã¯ä¸å¯):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sync ãŒå¤±æ•—ã™ã‚‹å ´åˆã¯ cp --recursive ã‚’ä½¿ç”¨\n",
    "# for model in HF_MODELS:\n",
    "#     local_dir = f\"/content/models/{model}\"\n",
    "#     dest_path = f\"models/{model.split('/')[-1]}\"\n",
    "#     !aws s3 cp --recursive {local_dir} s3://{BUCKET}/{dest_path} \\\n",
    "#         --region={REGION} \\\n",
    "#         --endpoint-url={ENDPOINT_URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœã®ç¢ºèª\n",
    "for model in HF_MODELS:\n",
    "    dest_path = f\"models/{model.split('/')[-1]}\"\n",
    "    print(f\"=== {dest_path} ===\")\n",
    "    !aws s3 ls s3://{BUCKET}/{dest_path}/ \\\n",
    "        --region={REGION} \\\n",
    "        --endpoint-url={ENDPOINT_URL}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}